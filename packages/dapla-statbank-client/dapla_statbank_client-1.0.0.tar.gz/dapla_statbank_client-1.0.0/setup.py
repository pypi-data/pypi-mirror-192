# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['statbank']

package_data = \
{'': ['*']}

install_requires = \
['IPython>=8.5.0,<9.0.0',
 'dapla-toolbelt>=1.3.3,<2.0.0',
 'ipywidgets>=8.0.2,<9.0.0',
 'pandas>=1.5.0,<2.0.0',
 'pyjstat>=2.3.0,<3.0.0',
 'requests>=2.28.1,<3.0.0']

setup_kwargs = {
    'name': 'dapla-statbank-client',
    'version': '1.0.0',
    'description': 'Handles data transfer Statbank <-> Dapla for Statistics Norway',
    'long_description': '# dapla-statbank-client\nUsed internally by SSB (Statistics Norway).\nValidates and transfers data from Dapla to Statbank.\nGets data from public and internal statbank.\n\n\n### Installing from Pypi with Poetry\nIf your project has been set up with `ssb-project create`, navigate into the folder with the terminal. `cd project-name`. Then install the package:\n```bash\npoetry add dapla-statbank-client\nssb-project build\n```\nMake a notebook with the project\'s kernel, try this code to verify that you can "log in":\n```python\nfrom statbank import StatbankClient\nstat_client = StatbankClient(loaduser = "LASTEBRUKER")\n# Change LASTEBRUKER to your load-statbank-username\n# Fill out password\n# Default publishing-date is TOMORROW\nprint(stat_client)\n# Printing will show you all the default settings on the client.\n# You can change for example date by specifying it: StatbankClient(loaduser = "LASTEBRUKER", date="2023-02-16")\n```\n\nBe aware that from the **dapla staging environment** you will be sending to statbank-TEMP-database, your changes will not be published. But if you are in the main dapla-jupyterlab (prod), you WILL publish to statbanken, in the PROD database. So pay extra attention to the **publishing-date** when in dapla-main-prod-jupyterlab.\n\n\n### Usage Transferring\n\n```python\nstat_client.transfer({"deltabellfilnavn.dat" : df_06399}, "06339")\n```\nThe simplest form of usage, is directly-transferring using the transfer-method under the client-class. The statbanktable expects named "deltabeller" in a dictionary, see `trasferdata_template()` below. This might be all you need if this data has been sent in the same shape to statbanken before... If you are unsure at all, keep reading.\n\n\n### Building datasets\nYou can look at the "filbeskrivelse" which is returned from `stat_client.get_description()` in its own local class: StatbankUttrekksBeskrivelse\n```python\ndescription_06339 = stat_client.get_description(tableid="06339")\nprint(description_06339)\n```\nThis should have all the information you are used to reading out from the old "Filbeskrivelse". And describes how you should construct your data.\n\nYour data must be placed in a datastructure, a dict of pandas dataframes. Take a look at how the dict should be constructed with:\n```python\ndescription_06339.transferdata_template()\n```\nThis both returns the dict, and prints it, depending on what you want to do with it. Use it to insert your own DataFrames into, and send it to .validate() and/or .transfer(). It might look like this:\n```python\n{"deltabellfilnavn.dat" : df_06399}\n```\n\nOther interesting attributes can be retrieved from the UttrekksBeskrivelse-object:\n```python\ndescription_06339.subtables\ndescription_06339.variables\ndescription_06339.codelists\ndescription_06339.suppression\n```\n\nAfter starting to construct your data, you can validate it against the Uttrekksbeskrivelse, using the validate-method, *without starting a transfer*, like this:\n```python\nstat_client.validate({"deltabellfilnavn.dat" : df_06399}, tableid="06339")\n```\nValidation will happen by default on user-side, in Python.\nValidation happens on the number of tables, number of columns, code usage in categorical columns, code usage in "suppression-columns" (prikkekolonner), and on timeformats (both length and characters used) and more.\n**This might be a lot of feedback**, but understanding this will help you to debug what might be wrong with your data, before sending it in.\nIf your data contains floats, it might hint at you to use the .round_data()-method to prepare your data, it uses the amount of decimals defined in UttrekksBeskrivelse to round UPWARDS (from pure 0.5 values) and convert to strings with comma as the decimal sign along the way, it is used like this:\n```python\ndata_dict_06339 = description_06339.round_data({"deltabellfilnavn.dat" : df_06399})\n```\n\n\n\n\n### Getting apidata\n\nThese functions can be imported directly and will then not ask for username and password, but are also available through the client...\n```python\nfrom statbank import apidata_all, apidata, apidata_rotate\n```\n\n```python\ndf_06339 = apidata_all("06339", include_id=True)\n```\n`apidata_all`, does not need a specified query, it will build its own query, trying to get *all the data* from the table. This might be too much, resulting in an error.\n\nThe `include_id`-parameter is a bit *magical*, it gets both codes and value-columns for categorical columns, and tries to merge these next to each other, it also makes a check if the content is the same, then it will not include the content twice.\n\nIf you want to specify a query, to limit the response, use the method `apidata` instead.\\\nHere we are requesting an "internal table" which only people at SSB have access to, with a specified URL and query.\n```python\nquery = {\'query\': [{\'code\': \'Region\', \'selection\': {\'filter\': \'vs:Landet\', \'values\': [\'0\']}}, {\'code\': \'Alder\', \'selection\': {\'filter\': \'vs:AldGrupp19\', \'values\': [\'000\', \'001\', \'002\', \'003\', \'004\', \'005\', \'006\', \'007\', \'008\', \'009\', \'010\', \'011\', \'012\', \'013\', \'014\', \'015\', \'016\', \'017\', \'018\', \'019\', \'020\', \'021\', \'022\', \'023\', \'024\', \'025\', \'026\', \'027\', \'028\', \'029\', \'030\', \'031\', \'032\', \'033\', \'034\', \'035\', \'036\', \'037\', \'038\', \'039\', \'040\', \'041\', \'042\', \'043\', \'044\', \'045\', \'046\', \'047\', \'048\', \'049\', \'050\', \'051\', \'052\', \'053\', \'054\', \'055\', \'056\', \'057\', \'058\', \'059\', \'060\', \'061\', \'062\', \'063\', \'064\', \'065\', \'066\', \'067\', \'068\', \'069\', \'070\', \'071\', \'072\', \'073\', \'074\', \'075\', \'076\', \'077\', \'078\', \'079\', \'080\', \'081\', \'082\', \'083\', \'084\', \'085\', \'086\', \'087\', \'088\', \'089\', \'090\', \'091\', \'092\', \'093\', \'094\', \'095\', \'096\', \'097\', \'098\', \'099\', \'100\', \'101\', \'102\', \'103\', \'104\', \'105\', \'106\', \'107\', \'108\', \'109\', \'110\', \'111\', \'112\', \'113\', \'114\', \'115\', \'116\', \'117\', \'118\', \'119+\']}}, {\'code\': \'Statsbrgskap\', \'selection\': {\'filter\': \'vs:Statsborgerskap\', \'values\': [\'000\']}}, {\'code\': \'Tid\', \'selection\': {\'filter\': \'item\', \'values\': [\'2022\']}}], \'response\': {\'format\': \'json-stat2\'}}\n\ndf_folkemengde = apidata("https://i.ssb.no/pxwebi/api/v0/no/prod_24v_intern/START/be/be01/folkemengde/Rd0002Aa",\n                                     query,\n                                     include_id = True\n                                    )\n```\n\n`apidata_rotate` is a thin wrapper around pivot_table. Stolen from: https://github.com/sehyoun/SSB_API_helper/blob/master/src/ssb_api_helper.py\n```python\ndf_folkemengde_rotert = apidata_rotate(df_folkemengde, \'tidskolonne\', "verdikolonne")\n```\n\n\n### Using a date-widget for publish day\nFor easier setting of the date on the client, after it has been initialized, you can use a date-picker in JupyterLab from ipywidgets.\n```python\ndate = stat_client.date_picker()\ndate\n# Do a cell shift here, run the cell above and then change the date, dont run the cell again\n# When this is then run, it should update the date on the client:\nstat_client.set_publish_date(date)\n```\n\n\n### Saving and restoring Uttrekksbeskrivelser and Transfers as json\n\nFrom `stat_client.transfer()` you will recieve a StatbankTransfer object, from `stat_client.get_description` a StatbankUttrekksBeskrivelse-object. These can be serialized and saved to disk, and later be restored, maybe this can be a form of logging on which transfers were done?\n\n```python\nfilbesk_06339 = stat_client.get_description("06339")\nfilbesk_06339.to_json("path.json")\n# Later the file can be restored with\nfilbesk_06339_new = stat_client.read_description_json("path.json")\n```\nSome deeper data-structures, like the dataframes in the transfer will not be serialized and stored with the transfer-object in its json.\n\n---\n\n### Version history\n- 1.0.0 Finished going through initial issues, less complaining from verify on floats\n- 0.0.11 Statbank people wanted a user-agent-requesst-header to differentiate test from prod\n- 0.0.9 After further user-testing and requests\n- 0.0.5 Still some parameter issues\n- 0.0.4 More test coverage, some bugs fixed in rounding checks and parameter-passing\n- 0.0.3 Removed batches, stripping uttrekk from transfer, rounding function on uttrekk, data required in as a dict of dataframes, with "deltabell-navn". Tableid now works to transfer to instead of only "hovedtabellnavn"\n- 0.0.2 Starting alpha, fine-tuning release to Pypi on github-release\n- 0.0.1 Client, transfer, description, apidata. Quite a lot of work done already. Pre-alpha.\n',
    'author': 'Statistics Norway',
    'author_email': 'None',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.10,<4.0',
}


setup(**setup_kwargs)

mydict = {
    "相关系数为0表明两个变量之间不存在任何关系": "T",
    "密度函数可以是负的。": "T",
    "当总体G1和G2为正态总体且协方差相等时，选用马氏距离。": "T",
    "标准化随机变量的协方差阵与原变量的相关系数相同。": "T",
    "样本相关系数r∈(－1,1)": "T",
    "如果相关系数为0，则表明两个变量间不存在线性相关。": "T",
    "一个行列式中某一行（列）所有元素的公因子可以提到行列式符号的外边。": "T",
    "numpy中产生全1的矩阵使用的方法是empty。": "T",
    "相关关系是指变量间不确定性的依存关系。": "T",
    "pandas中head(n)的意思是获取最后的n行数据。": "T",
    "Numpy的ndarray(数组)中，使用shape()来表示数组的维度尺寸。": "T",
    "Python语言是非开源的语言。": "T",
    "脸谱图是用脸部特征表达变量间的相关性。": "T",
    "通过对多变量的脸谱图分析，可以直观地对原始数据资料进行归类或比较研究。": "T",
    "设要分析的资料共有p个变量，当p值较大时一张雷达图也可以清晰表达各观测之间的接近程度。": "T",
    "雷达图是目前应用较为广泛的多元资料进行作图的方法，利用雷达图可以很方便地研究个样本点之间的关系并对样品进行归类。": "T",
    "星图和星座图很相似，甚至有的文献把两者看成是一回事。": "T",
    "利用星座图可以方便地对样本点进行分类，再星座图上比较靠近的样本点比较相似，可分为一类。": "T",
    "多变量的图表示法使资料的呈现方式更直观、更形象，可以作为定量分析的研究结果并形成结论。": "T",
    "只要变量的指标数目不变，对应脸谱图的特征就不变。": "T",
    "马氏距离在协差阵为单位阵时退化为欧氏距离。": "T",
    "马氏距离受单位的影响。": "T",
    "相关系数度量了两个随机变量之间依赖关系的强弱。": "T",
    "Cov(X,Y)=0, 称X与Y是不相关的。": "T",
    "随机向量X的协方差阵是对称矩阵。": "T",
    "若p维随机向量X的协方差阵存在,且每个分量的方差大于零，则X的相关阵的元素计算公式为:r_ij=(cov(X_i,X_j))/(D(X_i)D(X_j)),i,j=1,2,…,p。": "T",
    "设两个随机向量X和Y是相互独立的，F(x,y)为(X,Y)的联合分布函数，G(x)和H(y)分别为X和Y的分布函数，则F(x,y)=G(x)H(y)。": "T",
    "设两个随机向量X和Y是相互独立的，f(x,y)为(X,Y)的密度函数，g(x)和h(y)分别为X和Y的密度函数，则f(x,y)=g(x)+h(y)。": "T",
    "正态分布的条件分布仍为条件分布。": "T",
    "相关关系数不会取负值。": "T",
    "相关系数的绝对值不会大于1。": "T",
    "若A是退化矩阵，则A-1一定存在。": "T",
    "若A为p阶对称矩阵，则存在正交矩阵T和对角矩阵Λ=diag(λ_1,λ_2,⋯λ_p)，使得A=TΛT'。": "T",
    "若向量x和y的内积为0，则说明向量x和y垂直。": "T",
    "若A是一个正交矩阵，则A的行列式为1。": "T",
    "若A和B均为p阶方阵，则|AB|=|A||B|。": "T",
"单纯依靠相关与回归分析，无法判断事物之间存在的因果关系": "T",
    "距离判别法考虑到了误判之后所造成的损失的差异。": "T",
    "判别分析最基本要求是分组类型在两组以上且解释变量必须是可测量的。": "T",
    "在回归分析中，变量间的关系若是非确定关系，那么因变量不能由自变量唯一确定。": "T",
    "聚类分析仅能进行样本聚类。": "T",
    "聚类分析属于有指导的学习分类方法。": "T",
    "进行样品聚类分析时，“靠近”往往由某种距离来刻画。": "T",
    "类平均法进行系统聚类的的思想是来于方差分析，如果类分得正确，同类样品的离差平方和应当较小，类与类之间的离差平方和应当较大。": "T",
    "聚类分析时可通过碎石图确定最终的分类数。": "T",
    "针对同一多元数据，不同的方法聚类的结果相同。": "T",
    "系统聚类法中，对于那些先前已被“错误”分类的样品不再提供重新分类的机会。": "T",
    "K-均值法只能用于对样品的聚类，而不能用于对变量的聚类。": "T",
    "有序样品的聚类的实质上是需要找出一些分点，将数据划分成几个分段，每个分段看作一类，称这种分类也可称为分割。": "T",
    "k均值法的类个数需事先指定。": "T",
    "进行多元数据的指标聚类时，可根据相关系数或某种关联性度量来聚类。": "T",
    "最长距离法中，选择最小的距离作为新类与其他类之间的距离，然后将类间距离最小的两类进行合并，一直合并到只有一类为止。": "T",
    "K均值聚类分析中，样品一旦划入某一类就不可改变。": "T",
    "名义尺度的指标用一些类来表示，这些类之间有等级关系，但没有数量关系。": "T",
    "下图为应用SPSS软件制作的散点图矩阵，图中城镇人口比重与平均预期寿命存在强线性相关性。": "T",
    "如果相关系数为0，则表明两个变量间不存在线性相关。": "T",
    "聚类分析的目的就是把相似的研究对象归类。": "T",
    "判别分析中,若两个总体的协差阵相等,则 Fisher判别与距离判别等价。": "T",
    "一般而言，不同聚类方法的结果不完全相同": "T",
    "在系统聚类过程中，聚合系数越大，合并的两类差异越小。": "T",
"主成分分析时，对数据进行标准化的过程可能抹杀原始变量离散程度差异。": "T",
    "主成分分析要求数据来自于正态总体。": "T",
    "对来自多元正态总体的数据，主成分分析的主成分就是按数据离散程度最大的方向进行坐标轴旋转。": "T",
    "在主成分分析的过程中，得到的各个主成分的方差依次递减。": "T",
    "对于两组的判别，最大后验概率法的判别规则可使两个误判概率之和达到最小。": "T",
    "对于两组皆为正态组及协差阵相同的情形下，两组先验概率相同及两个误判代价也相等时的贝叶斯判别等价于距离判别，也等价于费希尔判别。": "T",
    "主成分分析实质上是线性变换，无假设检验。": "T",
    "一般地说，从同一原始变量的协方差矩阵出发求得的主成分与从原始变量的相关矩阵出发求得的主成分相同。": "T",
    "选取主成分还可根据特征值的变化来确定。\n求解主成分的过程实际就是对矩阵结构进行分析的过程。（T）（1分）": "T",
    "对于度量单位不同的指标或是取值范围彼此差异非常大的指标，可直接从协方差矩阵出发进行主成分分析。": "T",
    "主成分分析只是要达到目的的一个中间结果（或步骤），没有实际意义。": "T",
    "为了使得因子分析的结果更易于解释，进行正交因子旋转，旋转后，新的公共因子仍然彼此独立。": "T",
    "因子得分是为了考察每一个样品性质之间的关系。": "T",
    "因子分析中，载荷矩阵中的每一个元素代表的是变量Xi与公共因子Fj之间的关系。": "T",
    "因子分析中，利用主成分法求解的载荷系数与主成分分析中的主成分线性方程的系数一样。": "T",
    "因子分析中，公因子Fj的方差贡献表示的是公共因子Fj对于原始数据X中的每一分量Xi（i=1，2，…，p）所提供的方差的总和。": "T",
    "利用主成分法得到的因子载荷是唯一的。": "T",
    "主成分的数目大大少于原始变量的数目。": "T",
    "Logistic回归对于自变量有要求，度量变量或者非度量变量都不可以进行回归。": "T",
    "因子分析把变量分成公共因子和独立因子两部分因素。": "T",
    "因子载荷经正交旋转后,各变量的共性方差和各因子的贡献都发生了变化。": "T",
    "因子分析只能用于研究变量之间的相关关系。": "T",
    "主成分分析是将原来较少的指标扩充为多个新的的综合指标的多元统计方法。": "T",
    "Logistic回归对于自变量有要求,度量变量或者非度量变量都不可以进行回归。": "T",
    "因子载荷量是指因子结构中原始变量在因子分析时抽取出的公共因子的相关程度。": "T"
}

def fuzzy_match(dict, str):
    result = []
    for key in dict:
        if str in key:
            result.append([key, dict[key]])
    return result

def find(str):
    res = fuzzy_match(mydict, str)
    for i in res:
        print(i[0], i[1])